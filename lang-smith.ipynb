{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5f3142-bdd7-4060-8ad1-af9924bd9691",
   "metadata": {},
   "source": [
    "## Environment Setup - LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f386d8-2b7f-45e8-9b5e-bf229de413b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: openai in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.97.1)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (3.11.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (24.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langsmith) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Install necessary Python packages using pip:\n",
    "# 1. langsmith - for LangChain tracing, debugging, and evaluation\n",
    "# 2. openai - to interact with OpenAI models like GPT-3.5, GPT-4, etc.\n",
    "# 3. ollama - to connect with and use local LLMs like LLaMA/Mistral via the Ollama runtime\n",
    "!pip install langsmith openai ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebdb3a-ac50-4ba1-960c-b6763ab8aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system's environment variables\n",
    "import os\n",
    "\n",
    "# Enable LangChain Tracing v2 (used for debugging, visualizing, and monitoring LangChain executions)\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'  # Enables the newer version of LangChain tracing\n",
    "\n",
    "# Set your LangChain API key (this key is required to authenticate with LangChain services)\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "\n",
    "\n",
    "# Set the project name under which all traces will be grouped in LangSmith (LangChain's platform for tracing & evaluation)\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'Test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d11bf-1ed3-4806-90a5-9ae7ab9b0016",
   "metadata": {},
   "source": [
    "## Manually Curated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb9a4e-9930-41ed-b37e-fb626771e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and CSV operations\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Define the QA pairs\n",
    "# -------------------------\n",
    "\n",
    "# List of input questions related to DBRX model\n",
    "inputs = [\n",
    "    \"How many tokens was DBRX pre-trained on?\",\n",
    "    \"Is DBRX a MOE model and how many parameters does it have?\",\n",
    "    \"How many GPUs was DBRX trained on and what was the connectivity between GPUs?\",\n",
    "]\n",
    "\n",
    "# Corresponding answers to the questions above\n",
    "outputs = [\n",
    "    \"DBRX was pre-trained on 12 trillion tokens of text and code data.\",\n",
    "    \"Yes, DBRX is a fine-grained mixture-of-experts (MoE) architecture with 132B total parameters.\",\n",
    "    \"DBRX was trained on 3072 NVIDIA H100s connected by 3.2Tbps Infiniband\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: Create a structured dataset\n",
    "# -------------------------\n",
    "\n",
    "# Combine questions and answers into a list of dictionaries (each with 'question' and 'answer' keys)\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame (tabular format)\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Save the dataset to a CSV file\n",
    "# -------------------------\n",
    "\n",
    "# Define the full path where the CSV file will be saved (change the path as needed)\n",
    "csv_path = \"F:\\\\LangSmith\\\\DBRX_eval.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file without including the index column\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# At this point, you can upload the generated CSV file to LangSmith for evaluation or dataset creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1aaf1-ea5d-42ad-93b2-758c48112e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['c8b8d557-a1c7-48a2-9a5c-8083b6efd974',\n",
       "  'df818c21-02de-478c-93dc-013a21dbe990',\n",
       "  '2e1ec321-d8b9-4fd9-87c9-0a87841696ec'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LangSmith client for interacting with the LangSmith platform\n",
    "from langsmith import Client\n",
    "\n",
    "# Initialize the LangSmith client (uses environment variables for authentication)\n",
    "client = Client()\n",
    "\n",
    "# Define the name of the dataset to be created in LangSmith\n",
    "dataset_name = \"DBRX\"\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Create a new dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Create a new dataset on LangSmith with a name and description\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"QA pairs about DBRX model.\",  # Describes the purpose of the dataset\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Upload examples to the dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Upload the list of input-output pairs as examples to the dataset\n",
    "# `inputs` and `outputs` must be lists of dictionaries, one per example\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],   # Convert input questions to dict format\n",
    "    outputs=[{\"answer\": a} for a in outputs],   # Convert output answers to dict format\n",
    "    dataset_id=dataset.id                      # Associate the examples with the created dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bcedc1-3ee2-4dd4-97f1-6b9d66045fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['3d6cd2f6-edc5-4c90-a123-5186cfc39909'], 'count': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define additional QA pairs to be appended to the existing dataset\n",
    "new_questions = [\n",
    "    \"What is the context window of DBRX Instruct?\",\n",
    "]\n",
    "\n",
    "new_answers = [\n",
    "    \"DBRX Instruct was trained with up to a 32K token context window.\",\n",
    "]\n",
    "\n",
    "# ----------------------------------------\n",
    "# Add new examples to the existing dataset\n",
    "# ----------------------------------------\n",
    "\n",
    "# Use the same client and dataset ID to append the new question-answer pairs\n",
    "# This allows you to incrementally build your dataset over time\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in new_questions],   # Format the new question(s)\n",
    "    outputs=[{\"answer\": a} for a in new_answers],       # Format the new answer(s)\n",
    "    dataset_id=dataset.id                              # Link to the existing dataset\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
